{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify(label):\n",
    "  if label == 'NotNegative' or label == 'Positive':\n",
    "    return 'Positive'\n",
    "  if label == 'NotPositive' or label == 'Negative':\n",
    "    return 'Negative'\n",
    "  else:\n",
    "    return 'None'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def load_prediction(fname):\n",
    "  pred = {}\n",
    "  with open(fname) as f:\n",
    "    for line in f:\n",
    "      line_elem = json.loads(line.strip())\n",
    "      pred[line_elem['docId']] = {k['holder']+'##'+k['target']: k['sentiment'] for k in line_elem['sentiments']}\n",
    "  return pred\n",
    "\n",
    "def load_gold(fname):\n",
    "  gold = {}\n",
    "  with open(fname) as f:\n",
    "    for line in f:\n",
    "      line_elem = json.loads(line.strip())\n",
    "      gold[line_elem['docId']] = {k['holder']+'##'+k['target']: simplify(k['sentiment']) for k in line_elem['sentiments']}\n",
    "  return gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(p, r):\n",
    "  if r == 0.:\n",
    "    return 0.\n",
    "  return 2 * p * r / float(p + r)\n",
    "def f1_micro(true_and_prediction):\n",
    "  num_examples = len(true_and_prediction)\n",
    "  num_predicted_labels = 0.\n",
    "  num_true_labels = 0.\n",
    "  num_correct_labels = 0.\n",
    "  pred_example_count = 0.\n",
    "  for true_labels, predicted_labels in true_and_prediction:\n",
    "    if predicted_labels:\n",
    "      pred_example_count += 1\n",
    "    num_predicted_labels += len(predicted_labels)\n",
    "    num_true_labels += len(true_labels)\n",
    "    num_correct_labels += len(set(predicted_labels).intersection(set(true_labels)))\n",
    "  if pred_example_count == 0:\n",
    "    return num_examples, 0, 0, 0, 0, 0\n",
    "  precision = num_correct_labels / num_predicted_labels\n",
    "  recall = num_correct_labels / num_true_labels\n",
    "  avg_elem_per_pred = num_predicted_labels / pred_example_count\n",
    "  #return num_examples, pred_example_count, avg_elem_per_pred, precision, recall, f1(precision, recall)\n",
    "  return '{0:.1f}\\t{1:.1f}\\t{2:.1f}'.format(precision*100, recall*100, f1(precision, recall)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(pred, gold):\n",
    "  gold_pred_list = []\n",
    "  total_doc_count = 0\n",
    "  for doc_id, gold_i in gold.items():\n",
    "    if not doc_id in pred:\n",
    "      continue\n",
    "    total_doc_count += 1\n",
    "    for holder_target, pred_ii in pred[doc_id].items():\n",
    "      gold_pred = (gold_i.get(holder_target, 'None'), pred_ii)\n",
    "      gold_pred_list.append(gold_pred)\n",
    "  print(gold_pred_list[:10])\n",
    "  pos_list = [(int(g=='Positive'), int(p=='Positive')) for (g, p) in gold_pred_list]\n",
    "  pos_list = [([] if g == 0 else [1], [] if p == 0 else [1]) for (g, p) in pos_list]\n",
    "  neg_list = [(int(g=='Negative'), int(p=='Negative')) for (g, p) in gold_pred_list]\n",
    "  neg_list = [([] if g == 0 else [1], [] if p == 0 else [1]) for (g, p) in neg_list]\n",
    "  print(\"Positive\", f1_micro(pos_list))\n",
    "  print(\"Negative\", f1_micro(neg_list))\n",
    "  print(total_doc_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('None', 'None'), ('None', 'Negative'), ('None', 'None'), ('None', 'Negative'), ('None', 'Negative'), ('Negative', 'Negative'), ('None', 'None'), ('Negative', 'Negative'), ('None', 'Negative'), ('Negative', 'Negative')]\n",
      "Positive 44.4\t39.2\t41.6\n",
      "Negative 17.4\t30.4\t22.1\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "pred_model = load_prediction('/Users/echoi/Project/document-e2e-sent/prediction/dev.json')\n",
    "gold_ann = load_gold('/Users/echoi/Project/document-e2e-sent/data/annotation/acl_total.json')\n",
    "compute_f1(pred_model, gold_ann)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
